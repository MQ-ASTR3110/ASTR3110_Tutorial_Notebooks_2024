{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTR3110 Tutorial 2: Pandas\n",
    "\n",
    "Tutorial 2 of the *'Data Science Techniques in Astrophysics'* course at Macquarie University.\n",
    "\n",
    "## Learning outcomes from this tutorial\n",
    "\n",
    " * Understand the concept of a 'dataframe'\n",
    " * Learn how to read and write data into/out of a dataframe\n",
    " * Learn how to inspect and slice the tabular data\n",
    " * Practice common operations like adding columns and rows\n",
    " * Query a table using logical expressions.\n",
    " * Merge tables using join operations\n",
    " * Clean data of spurious entries.\n",
    " * Visualise the data in a table using common plots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  to Pandas\n",
    "\n",
    "The *pandas* module ([https://pandas.pydata.org/](https://pandas.pydata.org/)) is an open-source python-based data manipulation tool that originated in the comercial world and is now an industry standard. It is conceptually similar to a Microsoft Excel spreadsheet: it allows the user to perform operations on tables of data. *Pandas* is very well documented and there are excellent tutorials available online:\n",
    "\n",
    " * [Online Documentation](https://pandas.pydata.org/docs/)\n",
    " * [Official 'Getting Started' Guide](https://pandas.pydata.org/docs/user_guide/10min.html#min)\n",
    " * [Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Drive\n",
    "\n",
    "Today we will be operating on actual data, so we need to start by linking to our Google drive. If you are running this notebook on a local machine you can safely ignore this section.\n",
    "\n",
    "Open the [SETUP_COLAB](https://github.com/MQ-ASTR3110/ASTR3110_Tutorial_Notebooks_2022/blob/master/SETUP_COLAB.md) instructions in a new tab and copy the material to your Google drive. Go to drive.google.com, find the notebook 'ASTR3110_Tutorial_2_Pandas.ipynb' and open using Colab. Then make sure Google drive is mounted using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to mount your Google Drive space (IGNORE IF RUNNING LOCALLY)\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into the correct directory\n",
    "#cd gdrive/'My Drive'\n",
    "#BE SURE TO GO TO THE FOLDER THAT HAS THE GITHUB REPOSITORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in data\n",
    "\n",
    "The data we will be processing today is a catalogue of radio-bright objects detected by the Very Large Array. It consists of several different types of objects: HII Regions (ionised bubbles around high-mass stars), Planetary Nebulae (an end-phase of stellar evolution), Radio Stars (stars that have radio flares) and Radio Galaxies (black-holes in galaxies outside our own Milky Way. \n",
    "\n",
    "The data has been downloaded from the [project website](https://cornish.leeds.ac.uk/public/catalogue.php) as comma separated variables (CSV) files and is split into several parts.\n",
    "\n",
    "* DATA/CORNISH_HII.csv\n",
    "* DATA/CORNISH_PN.csv\n",
    "* DATA/CORNISH_STAR.csv\n",
    "* DATA/CORNISH_RG.csv\n",
    "\n",
    "Let's load each of these files into a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the other files have identical column names so we want to add a new column that contains an identifier for object type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the remaining catalogue files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massaging the catalogue tables\n",
    "\n",
    "Because the tables have exactly the same columns, we can concatenate them into a master catalogue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "The tables are simply stacked on top of each other, maintaining the same order as when they were read in. We might want to order them by coordinate in the Galactic reference frame (longitude and latitude):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that the leftmost numbers above are actually an index for the table. Currently these numbers derive from the line number that the rows occupied in their original CSV file. This may become confusing later on should we choose to use the index column to select out rows of interest. We can do several things to fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have retained the 'Name' column by specifying ```drop=False``` - by default it is dropped'. Had we dropped it, we could add it back in later by executing ```allDF[\"Name\"]=allDF.index```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary stats and missing data\n",
    "\n",
    "The are lots of convenience methods in Pandas dataframe objects. For example, the ```dataframe.describe()``` returns a dataframe with summary statistics of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the rows by their index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when accessing a single row or column, the result is returned as a *Pandas series*. A Pandas series is a much simpler data format compared to a dataframe. In fact, a dataframe can be thought of as several Pandas series joined together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the important ```.loc()``` method to address a row by its index value. We could also specify its row number using the ```.iloc()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many datasets will have missing data, which are set to NaN in a Pandas dataframe. To figure out where these are occuring do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
