{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASTR3110 Tutorial 10: CNNs\n",
    "Tutorial 10 of the 'Data Science Techniques in Astrophysics' course at Macquarie University.\n",
    "\n",
    "## Learning outcomes from this tutorial\n",
    "\n",
    " * Learn how to setup data to input into a convolutional neural network.\n",
    " * Learn how to build a convolutional neural network in the Keras framework.\n",
    " * Create diagnostic graphs and reports for a CNN to understand how well the training went.\n",
    " * Use a saved model to make a prediction for an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup for Google Drive\n",
    "\n",
    "Today we will be operating on a dataset of animal images, so start by linking to your Google drive. The dataset is available at this link: [[animals.tar.gz](https://drive.google.com/file/d/1dEdDPCg9_TkDEvyLgHDrEFYhRVgakt99/view?usp=sharing)]. Please download to your Google drive and then follow the below directions to store the data in the local Colab directory in which you are running your notebook:\n",
    "\n",
    "```\n",
    "# Link to Google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "#Copy animals.tar.gz to local directory (note the last dot means copy into the current directory)\n",
    "!cp gdrive/'My Drive'/animals.tar.gz .\n",
    "\n",
    "#make a DATA directory\n",
    "!mkdir DATA\n",
    "\n",
    "# Unpack the dataset\n",
    "!tar -xzf animals.tar.gz\n",
    "\n",
    "#Move the new folder into your DATA directory\n",
    "!mv animals DATA/\n",
    "```\n",
    "\n",
    "Note that the local Colab directory may not save these datafiles after you close down your session.\n",
    "\n",
    "## Setup for Colab\n",
    "\n",
    "Today we will be running CNNs, which can be slow when using CPUs to do the crunching, but using a GPU can speed things up substantially. It is recommended that you run this lab using Colab, and set up the notebook to utilize GPU acceleration. To do this, click the 'Edit' button at top left of the window, then 'Notebook Settings', then select 'GPU' from the 'Hardware accelerator' dropdown menu.\n",
    "\n",
    "## Quick overview of CNNs\n",
    "\n",
    "For a quick explanation of how a CNN works see [here](https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac), [here](https://www.cs.ryerson.ca/~aharley/vis/conv/) or [here](https://arxiv.org/abs/1511.08458). For a free detailed course with deep mathematical background, see [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the data\n",
    "\n",
    "In this dataset the train-validation-test split has already been done, so we just need to read in the images in each directory and put them into the format expected by the CNN.\n",
    "\n",
    "The data are in the \"animals\" directory with images sorted into sub-directories that are split into test, train, valid directories, each with subdifrectories for each of the classes (cat, dog, panda). That is:\n",
    "\n",
    "```\n",
    "animals/\n",
    "├── test\n",
    "│   ├── cat\n",
    "│   ├── dog\n",
    "│   └── panda\n",
    "├── train\n",
    "│   ├── cat\n",
    "│   ├── dog\n",
    "│   └── panda\n",
    "└── valid\n",
    "    ├── cat\n",
    "    ├── dog\n",
    "    └── panda\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use [glob](https://docs.python.org/3/library/glob.html) to return a list of all of the images, which can then be used to read our data in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the images and see what needs to be done to get them into the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are RGB colour images, with different widths and heights, and pixel range 0 to 255. We need to loop over each of the lists, read in each image, normalise to 0-1, and resize onto a consistent size. We also need to generate the label for each image using the pathname and some tricky string manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of images in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to make one-hot binarized labels like we did for the ANNs last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN\n",
    "\n",
    "Now it is time to build the model. Like the ANN, we create a sequential stack of layers. However, these layers accept 3D images with a width, height and depth. CNNs also tend to have repeating blocks of layers that do:\n",
    "\n",
    "```\n",
    "Convolution -> Activation - > Binning (downsize images)\n",
    "```\n",
    "\n",
    "The convolutional layer processess the image by convolving it with a number of small filters (usually 3x3). These filters start out as noise, but are changed by the training process to detect differet 'textures' in the images. \n",
    "\n",
    "The binning layer we use here is called ```MaxPooling``` and shrinks the resolution of the output by 1/2 (see [here](https://computersciencewiki.org/index.php/Max-pooling_/_Pooling)). So as the image passes through the network it is reduced in size and the relative scale of the filters changes. \n",
    "\n",
    "Let's define simple network. The CNN accepts an array of 3D images (compare this to the ANN, which accepts an array of flattened 1D vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose an optimiser (default to stochastic gradient descent) and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier\n",
    "\n",
    "Now we set the final training parameters and train the CNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the classifier and training session\n",
    "\n",
    "Let's start by visualising the training curves. We will make a function to do this and format it nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not going to go through the plotting code -- go through in your own time to familiarise yourself with\n",
    "#what this is doing. Similar to plotting code from ANN notebook, but now the loss and accuracy are plotted\n",
    "#on separate subplots so that it is easier to see how they change.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set larger font sizes\n",
    "mpl.rcParams[\"font.size\"] = 12.0\n",
    "\n",
    "def plot_train_curves(H):\n",
    "\n",
    "    # Create the figure\n",
    "    fig = plt.figure(figsize=(14., 6.))\n",
    "    \n",
    "    # Sub-plot for the loss curves\n",
    "    ax1 = fig.add_subplot(1,2,1)    \n",
    "    epoch = range(1, len(H[\"loss\"])+1)\n",
    "    ax1.step(epoch, H[\"loss\"], where=\"mid\", label=\"Train Loss\")\n",
    "    ax1.step(epoch, H[\"val_loss\"], where=\"mid\", label=\"Valid Loss\")\n",
    "    ax1.legend(loc=\"best\", shadow=False, fontsize=\"medium\")\n",
    "    ax1.set_title(\"Model Loss [Epoch {:d}]\".format(epoch[-1]))\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    \n",
    "    # Sub-plot for the accuracy curves\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    ax2.step(epoch, H[\"accuracy\"], where=\"mid\", label=\"Train Accuracy\")\n",
    "    ax2.step(epoch, H[\"val_accuracy\"], where=\"mid\", label=\"Valid Accuracy\")\n",
    "    ax2.legend(loc=\"lower right\", shadow=False, fontsize=\"medium\")\n",
    "    ax2.set_title(\"Model Accuracy [Epoch {:d}]\".format(epoch[-1]))\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "\n",
    "    # Apply nice formatting\n",
    "    ax1.tick_params(pad=7)\n",
    "    for line in ax1.get_xticklines() + ax1.get_yticklines():\n",
    "        line.set_markeredgewidth(1)\n",
    "        ax2.tick_params(pad=7)\n",
    "    for line in ax2.get_xticklines() + ax2.get_yticklines():\n",
    "        line.set_markeredgewidth(1)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the function to plot the training curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that after 50 epochs the training loss is still trending down and the training accuracy is still climbing, however, the validation curves have all but plateaued. We could probably train for more time and reach greater accuracy, but in this case it looks like the model is starting to overfit. A flattened validation accuracy curve and a climbing training curve (i.e., diverging) is a sign of overfitting. To improve the model, we probably need to experiment with the number of hidden layers and/or their thickness. We could also 'augment' that data to increase the number of training images by, e.g., flipping the images, rotating the images etc.\n",
    "\n",
    "Now evaluate the model's performance in numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way to look visualise predictions is to make a confusion matrix. This has true labels on one axis and predicted labels on another. A perfect classifier has only entries in the diagonal meaning that all images were correctly labelled. We can pull the code used to plot the confusion matrix from the week 8 lectorial notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from Random forests lectorial -- go through in own time to understand.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Oranges):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Source: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.figure(figsize = (10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, size = 24)\n",
    "    plt.colorbar(aspect=4)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
    "    plt.yticks(tick_marks, classes, size = 14)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    # Labeling the plot\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), fontsize = 20,\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "#    plt.grid(None)\n",
    "#    plt.tight_layout()\n",
    "    plt.ylabel('True label', size = 18)\n",
    "    plt.xlabel('Predicted label', size = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the model to make predictions\n",
    "\n",
    "We can use the models to make a prediction for a new image. We need to load and pre-process the image. Note that the exact same steps need to be performed on the input image as we did for our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
